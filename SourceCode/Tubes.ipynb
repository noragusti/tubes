{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tubes.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXhyxakfjqMq"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://github.com/noragusti/tubes/raw/main/Dataset.zip\\\n",
        "    -O /tmp/Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hlb6uWPTjuzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract file zip dataset\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/Dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "a2IOG0nAj06r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp/Dataset'\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "val_dir = os.path.join(base_dir, 'Validation')\n"
      ],
      "metadata": {
        "id": "aoaXEJJej4dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diseased_train_path = train_dir + '/diseased'\n",
        "healthy_train_path = train_dir + '/healthy'\n",
        "diseased_val_path = val_dir + '/diseased'\n",
        "healthy_val_path = val_dir + '/healthy'\n",
        "\n",
        "\n",
        "diseased_len_train = len(os.listdir(diseased_train_path))\n",
        "healthy_len_train = len(os.listdir(healthy_train_path))\n",
        "diseased_len_val = len(os.listdir(diseased_val_path))\n",
        "healthy_len_val = len(os.listdir(healthy_val_path))\n",
        "\n",
        "print(\"jumlah dataset Training : \", diseased_len_train + healthy_len_train)\n",
        "print(\"jumlah dataset validasi : \", diseased_len_val + healthy_len_val)\n",
        "print(\"\\n\\n\")\n",
        "print(\"jumlah train kelas diseased : \", diseased_len_train)\n",
        "print(\"jumlah train kelas healthy : \", healthy_len_train)\n",
        "print(\"jumlah validasi kelas diseased : \", diseased_len_val)\n",
        "print(\"jumlah validasi kelas healthy : \", healthy_len_val)"
      ],
      "metadata": {
        "id": "SYUPBNN2j6vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "oBWqnhrXj91O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n"
      ],
      "metadata": {
        "id": "h-A2OR8fkA4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Import Library yang dibutuhkan\n",
        "'''\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Flatten,Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "K1VQXdbnkDF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "definisikan dan setting callback untuk :\n",
        "1. memantau performa model\n",
        "2. melakukan save model terbaik menggunakan model checkpoint\n",
        "3. memberhentikan pelatihan ketika tidak memnuhi syarat dalam parameter earlystopping\n",
        "'''\n",
        "\n",
        "callbacks = EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='auto')        \n",
        "directory_to_save_best_model_file = '/content/gdrive/MyDrive/Colab Notebooks/Tubes/model_drop_batch_weight_from_callback_2.h5'\n",
        "best_model = ModelCheckpoint(directory_to_save_best_model_file, monitor='val_accuracy', verbose = 1, save_best_only = True)"
      ],
      "metadata": {
        "id": "pmgaRqonkHAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "definisikan pretrained model yang ingin digunakan\n",
        "'''\n",
        "\n",
        "VGG16_base = tf.keras.applications.VGG16(include_top=False, weights='imagenet', #include_top = false , berarti fully connected layer akan dipidah dari arsitektur\n",
        "                                                 input_tensor=None, input_shape=(224, 224,3))"
      ],
      "metadata": {
        "id": "nPqqEa-akJpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "melakukan setting bahwa model pretrained tidak akan dilatih ulang\n",
        "'''\n",
        "\n",
        "VGG16_base.trainable = False"
      ],
      "metadata": {
        "id": "_1tfB6ipkNem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "mendefinisikan layer pada bagian fully connected layer\n",
        "'''\n",
        "\n",
        "print('Adding new layers')\n",
        "output = VGG16_base.get_layer(index = -1).output  \n",
        "output = Flatten()(output)\n",
        "output = Dense(256,activation = \"relu\")(output)\n",
        "output = BatchNormalization()(output)\n",
        "output = Dropout(0.5)(output)\n",
        "output = Dense(256,activation = \"relu\")(output)\n",
        "output = BatchNormalization()(output)\n",
        "output = Dropout(0.5)(output)\n",
        "output = Dense(1, activation='sigmoid')(output) \n",
        "print('New layers Finishing Added!!!!')"
      ],
      "metadata": {
        "id": "MzhgWK6YkP_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_model = Model(VGG16_base.input, output)\n",
        "\n",
        "VGG16_model.summary()"
      ],
      "metadata": {
        "id": "jEULSkHwkSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', \n",
        "                        metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "o_3zSiZBkVDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = VGG16_model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=5,  # images = batch_size * steps\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=2,  #  images = batch_size * steps\n",
        "      callbacks = [callbacks, best_model])"
      ],
      "metadata": {
        "id": "nuxNg4KpkYNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LhWYqKzlkhsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import some of library that we need to look the confusion matrix, recall, f1_score, and accuracy score to look how much your model is well\n",
        "import numpy as np \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')"
      ],
      "metadata": {
        "id": "1hDwklcdkmBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model to evaluate more depth\n",
        "from keras.models import load_model\n",
        "model_path =  '/content/gdrive/MyDrive/Colab Notebooks/Tubes/model_drop_batch_weight_from_callback_2.h5'\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "id": "w-6mXygikoUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_metrics(y_true, y_pred):\n",
        "    accuracy=accuracy_score(y_true, y_pred)\n",
        "    precision=precision_score(y_true, y_pred,average='weighted')\n",
        "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1Score))\n",
        "    cm=confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1Score\n",
        "\n",
        "height=224; width=224\n",
        "batch_size=20\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "TESTING_DIR = val_dir\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(TESTING_DIR,\n",
        "                                                  batch_size=batch_size,                                                             \n",
        "                                                  target_size=(height, width),\n",
        "                                                  class_mode= None,\n",
        "                                                  shuffle=False\n",
        "                                                  )\n",
        "\n",
        "predictions = model.predict_generator(generator=test_generator)\n",
        "yPredictions = predictions > 0.5\n",
        "true_classes = test_generator.classes\n",
        "class_names = test_generator.class_indices\n",
        "Cmatrix_test = confusion_matrix(true_classes, yPredictions)\n",
        "\n",
        "testAcc,testPrec, testFScore = my_metrics(true_classes, yPredictions)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "ax= plt.subplot()\n",
        "data = np.asarray(Cmatrix_test).reshape(2,2)\n",
        "sns.heatmap(data,annot=True, fmt='',ax=ax, cmap=plt.cm.Reds)\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels') \n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(class_names)   \n",
        "ax.yaxis.set_ticklabels(class_names)\n",
        "plt.title('Confusion Matrix Test',fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3go23D_Akqul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(true_classes, yPredictions, target_names=class_names))"
      ],
      "metadata": {
        "id": "QcknjdvBBvsQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}